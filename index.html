<!DOCTYPE html>
<html>
<head>
    <title>UeX Portfolio 2024 Dhruva</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0">
    <link rel="stylesheet" type="text/css" href="style.css">
    <script src="js/three.min.js"></script>
    <script src="js/ShaderLoader.js"></script>
    <script src="js/StackBlur.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/seamless-scroll-polyfill@latest"></script>
</head>
<body>
    <div id="container">

        <div id="loadingScreen">
            <!-- Loading screen content (could be a spinner, logo, etc.) -->
            <!-- <p>Loading...</p> -->
            <p id="number"></p>
        </div>

        <div id="imageOverlay" style="display: none;">
            <div class="overlay-content">
                <span id="closeOverlay" style="cursor: pointer;">&times;</span>
                <img id="overlayImage" src="" alt="Image description">
                <p id="imageDescription">Image description here</p>
            </div>
        </div>
        
    
        <div id="titlePage" class="section">
            <div id="title-container">
                <div class="title">
                    <h1>Experience Design Portfolio</h1>
                    <h2>Dhruva Gowda Storz</h2>
                </div>

            </div>

            <div id="intro">
                <div class="background-container" id="intro-background">
                    <div class="intro-box">
                        <h3>UeX Experience Design 2023</h3>
                        <p id="intro-text">
                            This portfolio documents the outputs and methodologies of six projects in the experience design course run by the Media x Design Laboratory at EPFL Lausanne.
                            Each project focuses on a different type of design thinking, and incorporates a different functionality within midjourney.                    </p>
                        <p>
                            
                            The images in this website were generated by the Midjourney generative artificial intelligence based on design prompts and careful curation 
                            and inpainting.

                        </p>
                        <p>
                            The backgrounds you see were created by generating a depth map from Midjourney images using the Midas network through automatic1111's stable diffusion webui and thygate's extension plugin for depth map generation.
                            The three.js code for visualizing the point clouds were adapted from Ugo Capeto's depth player, which in turn is based on code by Jaume Sanchez (@thespite), both of which are under the MIT license.
                        </p>
                        <p>
                            Most importantly, this website was created using ChatGPT. While it demanded some manual intervention, 90% of the image content, structure, code and debugging involved the assistance of human-guided artificial intelligence.
                        </p>
                    </div>
                </div>
            </div>
    
        </div>
        <div class="spacer">

        </div>


        <div id="verticalNav">
            <div class="nav-circle" data-target="#titlePage"><span>Home</span></div>
            <div class="nav-circle" data-target="#empathy"><span>Empathy</span></div>
            <div class="nav-circle" data-target="#blending"><span>Blending</span></div>
            <div class="nav-circle" data-target="#context"><span>Context</span></div>
            <div class="nav-circle" data-target="#decomposition"><span>Decomposition</span></div>
            <div class="nav-circle" data-target="#style"><span>Style</span></div>
            <div class="nav-circle" data-target="#analogy"><span>Analogy</span></div>
        </div>

        <div id="titlePage-box" class="parallax-box">
            <!-- <img src="assets/demeterdepth.png"> -->
        </div>
        
        
        <div id="empathy" class="section">
            <div class="section-main">
                <!-- <div class="text-box">
                    <h3>Design by</h3>
                </div> -->
                <h2 class="section-title">Empathy</h2>
                <h1 class="section-header">Mobility for Mental Health</h1>
            </div>



            <div class="background-container">
                <p class="background-description">In design by empathy, our design process is centered around personas that exemply common human archetypes. 
                    By imagining ourselves in the shoes of a persona, we investigate how speculative design solutions can touch the mental, emotional, and physical experiences of others. 
                </p>

            <div class="content-row">
                <img class="grid-image" src="assets/empathy_luca.png" alt="Description" data-description="Our persona: Luca">
                <div class="text-column">
                    <h3>Lone Rider Luca</h3>
                    <p>Luca is a 23 year old student at EPFL, and like many of his colleagues he has a long journey ahead of him every morning and evening, this particular train ride seems to last forever. His restless mind briefly breaks free of the usual autopilot his mind goes into during travel, that keeps him sane on these long periods of repetition. With the gentle piano of Bill Evans' "My Foolish Heart" playing, Luca observes the expressionless faces around him, adhering to the unspoken social norms of solitude, and each within their own worlds. He thinks about how trains and buses are indistinguishable from one another, like instances of some programming code, their sterile, industrial interiors unbroken except from some small vestige of human influence. A bit of dirt on the floor from someone's shoe, or a stray plastic wrapper that escaped the pocket of an unaware passenger. Luca's train rides, designed to be neither enjoyable nor unpleasant, are merely a routine to endure.
                    </p>
                    <p>
                        This highlights a key issue with public transport: it fulfills its functional role but misses an opportunity for more. Could these spaces, with their neutral, industrial interiors, be transformed into mobile mental health sanctuaries?
                    </p>
                </div>
            </div>
            <div class="content-row">
                <img class="grid-image" src="assets/empathy_meditation.png" alt="Description" data-description="An illustrative example of design interventions for mental health on public transport">
                <div class="text-column">
                    <h3>Repurposing Public Transport for Mental Health</h3>
                    <p>
                        Mental health is an escalating concern in todays society, with rising rates of depression, and a growing sense isolation and alienation in modern society. Swiss institutions are addressing this, but more can be done. Not all modes of potential mental health intervention are being utilized to the extent they could be. Public transport in particular is a severely underutilized opportunity due to the sheer number and variety of lives it touches.
                    </p>
                    <p>
                        Trains and buses today are designed to provide a regular and consistent experience to travelers, fading into the background of their lives. Despite the rich diversity of a train's occupants, public transport interiors are in-between spaces, neither here nor their, a transitory place that rejects all attachment. Like other in-between spaces such as elevators, they follow unspoken social rules of solitude, that can make them deeply isolating and alienating experiences. Redesigning these spaces to be positive instead of neutral could be used to enhance mental well-being, which could also serve to boost its usage and support Lausanne's climate sustainability goals.
                    </p>
                    <p>
                        We propose two speculative designs in answer to this: Social Transport and Nature in Motion.
                    </p>
                </div>
            </div>

            <div class="column-container">
                <div class="image-text-column">
                    <img class="grid-image" src="assets/empathy_moss.png" alt="Description1" data-description="Nature in Motion: reimagining public transport as mobile gardens.">
                    <div class="column-text">
                        <h3>Nature In Motion</h3>
                        <p>Nature in Motion redesigns public transport vehicles as mobile gardens. The design involves the introduction of vertical gardens within buses, trains and metro cars, turning what is a tedious and often alienating experience into a meditative and therapeutic one, leveraging the calming and restorative properties of nature and touching the lives of a large number of Lausanne's residents to improve their mental health. Careful selection of plants and mosses with particular scents augments the olfactory experience of public transport, transforming the smell of machine and grease to an aroma-therapeutic experience.
                        </p>
                        <p>
                            As all gardens are unique, they will serve to differentiate the interiors of transport vehicles, which suffer from an industrial regularity that rejects attachment to the space. Nature in Motion allows passengers to build familiarity with the vehicles they travel in every day.
                        </p>
                    </div>
                </div>
        
                <div class="image-text-column">
                    <img class="grid-image" src="assets/empathy_tinder.png" alt="Description2" data-description="Social Transport: stimulating conversation in neutral transport spaces.">
                    <div class="column-text">
                        <h3>Social Transport</h3>
                        <p>Social Transport transforms the mundane routine of public transport into a lively social experience. This innovative app breaks the unspoken rules of isolation in transit, turning buses and trains into dynamic spaces for social connections. With an average of 58 minutes spent by Swiss passengers on public transport daily, the app capitalizes on this time to foster new interactions. By matching users with fellow commuters sharing similar routes and interests, it uncovers hidden opportunities for connection within one's daily commute.
                            </p>
                            <p>
                                Beyond just travel, Social Transport cultivates a sense of community on the move. It enables passengers to engage in conversations, expand their social networks, and form meaningful relationships, enriching each journey with social interactions. It's a step towards reimagining public transport as an inviting and interactive space, enhancing personal and communal experiences
                            </p>
                    </div>
                </div>

                </div>
            </div>
        
            
        </div>
        <div class="spacer">
        </div>

        <div id="blending" class="section">
            <div class="section-main">
                <h2 class="section-title">Blending</h2>
                <h1 class="section-header">Bringing Amusement Back to Amusement Parks</h1>
            </div>


                <div class="background-container">
                    <p class="background-description">In Design by Blending we explore how Midjourney's blend function can be used to synthesize new designs from a collection of images.
                    </p>

                    <div class="content-row">
                        <img class="grid-image" src="assets/blending_reconstructed.png" alt="Description" data-description="We aim to improve an abandoned amusement park through a design intervention">
                        <div class="text-column">
                            <h3>Abandoned Amusement Park</h3>
                            <p>Our blending design process targets an abandoned amusement park as the focus of a design intervention. 
                                The intention is to revive or amplify these spaces through a design concept obtained throuhg a blending approach. 
                                Abandoned amusement parks are especially interesting places as they straddle the fine line between creepy and fun. 
                                Although abandoned rides pose a risk after years of disuse, these places are often perfectly great, and could be reused.
                            </p>
                        </div>
                    </div>
                    <div class="content-row">
                        <img class="grid-image" src="assets/blending_collage.png" alt="Description" data-description="The images used to create a style reference by blending">
                        <div class="text-column">
                            <h3>Collage for Blending</h3>
                            <p>
                                Midjourney's blending funtion takes two or more images and combines them into one. To this end, we select a set of aesthetic inspirations we would like
                                to use for our blending process.
                            </p>
                        </div>
                    </div>
                    <div class="content-row">
                        <img class="grid-image" src="assets/blending_hybrid.png" alt="Description" data-description="The style reference image created by blending">
                        <div class="text-column">
                            <h3>Reference Image</h3>
                            <p>
                                Blending all of our inspiration images together gives us a single stylistic reference image that we can then
                                blend with our original source image. We seperate this process as the original image risks being lost. Blending 
                                only a reference and style image together gives them equal relative importance. 
                            </p>
                        </div>
                    </div>
                    <div class="content-row">
                        <img class="grid-image" src="assets/blending_mixed.png" alt="Description" data-description="Images generated by blending the original with the style reference">
                        <div class="text-column">
                            <h3>Design Exploration</h3>
                            <p>
                                We explore the generative solution space that results from blending our source image and our style reference obtained from our collage.
                                Finally, we select one design and iterate on it to improve it and make it more practical.
                            </p>

                        </div>
                    </div>

        
                    <div class="column-container">
                        <div class="image-text-column" id="blending-final">
                            <img class="grid-image" src="assets/blending_final.png" alt="Description1" data-description="The Great Ferris Broadcast Tower">
                            <div class="column-text">
                                <h3>The Great Ferris Broadcast Tower</h3>
                                <p>
                                    Our final design involves converting the monumental ferris wheel into a broadcast tower. Often, simply bringing a speaker
                                    into a space is all that is needed to get people to assemble. Using the towering ferris wheel as a scaffold for this speaker creates
                                    a monument that draws people around it, reintroducing life and amusement to abandonded amusement parks. This structure is especially well
                                    suited for music festivals and public gatherings as amusement parks are often outside of city limits and therefore would not interfer with 
                                    city noise laws. 
                                </p>
                            </div>
                        </div>
        
                        </div>
                    </div>
        </div>
        <div class="spacer">

        </div>

        <div id="context" class="section">
            <div class="section-main">
                <h2 class="section-title">Context</h2>
                
                <h1 class="section-header">Designing a Better Athens for Dogs</h1>
            </div>

                <div class="background-container">
                    <p class="background-description">In Design by Context, we aim to solve a design problem through a careful analysis of context. In this case, we investigate design solutions for giving the strays of athens a better life.
                    </p>


                    <div class="content-row">
                        <img class="grid-image" src="assets/context_athens_sq.png" alt="Description" data-description="Strays overlooking">
                        <div class="text-column">
                            <h3>The Strays of Athens</h3>
                            <p>There are 2 million stray dogs living in Athens. Since accusations of animal cruelty to the cityâ€™s mayor all dog catchers were sacked and a lack of a neutering program ensures that the dog population is steadily on the rise and uncontrolled. Many of these dogs coexist with humans, but many also suffer due to lack of food and medical care, There are many compassionate Greeks in Athens, but most are indifferent or have problems with the enormous dog population. There is therefore an urgent need for interventions to ensure a better coexistence between humans and animals in this great city.
                            </p>
                        </div>
                    </div>
                    <div class="content-row">
                        <img class="grid-image" src="assets/demeterimage.webp" alt="Description" data-description="Our dogsona Demeter in a landfill site">
                        <div class="text-column">
                            <h3>Fyli Landfill</h3>
                            <p>
                                Landfill sites outside of athens are not only dumping grounds for enormous amounts of waste, but also pets. Many irresponsible owners dump their dogs in areas like Fyli landfill outside athens. Food waste from unsold goods at supermarkets  gives abandoned dogs a means to survive, but it is often contaminated, rotting, or contains compounds poisonous to them. As a result, these landfill sites are full of abandoned dogs that are sick and suffering. We aims to solve both of these problems in one go, leveraging supermarket waste to give these landfill dogs a better life.
                            </p>

                        </div>
                    </div>
        
                    <div class="column-container">
                        <div class="image-text-column" id="blending-final">
                            <img class="grid-image" src="assets/context_trash.png" alt="Description1" data-description="Pipe Dream">
                            <div class="column-text">
                                <h3>Pipe Dream</h3>
                                <p>

                                    Pipe dream is part art intervention, and part robotic food sorting system for supermarket waste. 
                                    The device scans and separates food waste from supermarkets into food that is edible for dogs 
                                    and food that isn't, ensuring that they have a supply of healthy food. 
                                    The design of the device is influenced by the monolith in Stanley Kubrick's 2001: A Space Odyssey
                                     to juxtapose the existence of such a hypothetical device in a place as intentionally 
                                     alien and remote as a landfill site and force these sites into public view.  
                                     The actual mechanism of the sorting system is hidden from the viewer, representing a 
                                     "pipe dream" of no more abandoned dogs and no more food waste.
                                    
                                </p>
                            </div>
                        </div>
        
                        </div>
                    </div>

        </div>
        <div class="spacer">

        </div>

        <div id="decomposition" class="section">
            <div class="section-main">
                <h2 class="section-title">Decomposition</h2>
                <h1 class="section-header">Repurposing Laboratory Glass Waste</h1>
            </div>

            <div class="background-container">
                <p class="background-description">
                    In design by decomposition, we decompose a design problem into subcomponents and explore a solution space by surrendering our creative control
                    to a morphological box, and finding design solutions systematically rather than by inspiration.
                </p>

                <div class="content-row">
                    <img class="grid-image" src="assets/decomposition_morpho.png" alt="Description" data-description="Our Morphological Box">
                    <div class="text-column">
                        <h3>The Morphological Box</h3>
                        <p>
                            The morphological box is means of exploring different permutations and combinations of smalled design choices.
                            By discarding unfeasible or less compelling combinations, we can gradually pare down our solution space until we find a design we like.
                            In our case, we settle on the following design elements
                        </p>
                    </p>
                    <p>
                                Artist, Using, Houseware, Melted, Medical/Research Glass Waste, Relaxed
                    </p>
                    <p>
                        This combination especially resonated with us as medical or research glass is not talked about enough. 
                        lass used in research and medicine is made of borosilicate which has a higher melting point compared 
                        to standard glass waste, and is therefore not recycled. 
                        This glass is made to widthstand high temperatures with superior drop resistance and 
                        a non-porous surface. These properties make the material ideal for houseware for cooking and cleaning.

                    </p>
                    </div>
                </div>
                <div class="content-row">
                    <img class="grid-image" src="assets/decomposition_initial.png" alt="Description" data-description="An initial design concept of our chosen morphological box combination">
                    <div class="text-column">
                        <h3>Initial Output</h3>
                        <p> We obtain an output image from our chose
                        </p>
                        <P>
                                    An artist using houseware made of melted medical/research glass waste in a relaxed atomosphere
                        </P>
                        <p>
                            Gives us an initial image for a design concept that we can refine further.
                        </p>
                    </div>
                </div>
                <div class="content-row">
                    <img class="grid-image" src="assets/decomposition_wares.png" alt="Description" data-description="The product design developed through refinement of the initial morphological concept">
                    <div class="text-column">
                        <h3>The Final Product</h3>
                        <p>
                            We refine our initial image further by weighting each of our words (e.g. relaxed::1.3) to further explore 
                            the generative latent space of possible designs for our morphological combination, ultimately arriving at a product design
                            that we like.
                        </p>
                        <p>
                            Our final product design for housewares made of melted medical glass waste especially resonated with us 
                            due to the biological motiefs present within them. Medical and research waste are often associated with
                            death, disease or potential harm. This design helps break that stigma.
                        </p>
                    </div>
                </div>
    
                <div class="column-container">
                    <div class="image-text-column" id="blending-final">
                        <img class="grid-image" src="assets/decomposition_shop.png" alt="Description1" data-description="The concept store for GlassWare, developed through the morphological box method">
                        <div class="column-text">
                            <h3>GlassWare</h3>
                            <p>
                                Based on our product, we generate a consumer experience through midjourney called GlassWare, a store for designer houseware made of recycled medical and research glass waste.

                                Our experience center aims to help convince consumers to purchase houseware made of recycled 
                                research waste by breaking the stigma surrounding it. The entire cleaning, treating, melting and blowing process 
                                is exhibited, ensuring transparency about our sustainability and thoroughness. 

                            </p>
                        </div>
                    </div>
    
                    </div>
                </div>
            
        </div>
        <div class="spacer">

        </div>

        <div id="style" class="section">
            <div class="section-main">
                <h2 class="section-title">Style</h2>
                <h1 class="section-header">Reimaging the Electrolarynx</h1>
            </div>

                <div class="background-container">
                    <p class="background-description">In Design by Style, style plays a central focus in (re)imagining the future of healthcare. Through Midjourney, we fuse a patent diagram of a medical device (the function) with a style reference (the form) to explore new designs for healthcare products of the future.
                    </p>

                    <div id="content-row-1" class="content-row">
                        <img class="grid-image" src="assets/style_electrolarynx.png" alt="Description" data-description="Patent Diagram of the Electrolarynx">
                        <div class="text-column">
                            <h3>The Electrolarynx</h3>
                            <p>The electrolarynx is a medical device for people who have have lost the ability to use their vocal chords.
    
                            </p>
                            <p>
                                The device supplements the function of the  vocal chords by producing an acoustic vibration that when held to the throat is conducted through the skin and carries through the airways, allowing a patient to speak once again.
                            </p>
                            <p>
                                The sound produced by the electrolarynx is monofrequency, resulting in artificial and robotic sounding speech when used. Despite the growing occurrences of laryngectomies, this device has not seen a lot of innovation. Available electrolarynxes offer rudimentary pitch modulation with some startups experimenting with AI based prediction systems.
                            </p>
                            <p>
                                We reimagine the electrolarynx by borrowing tech from the vibrant electronic music synthesis community.
                            </p>
                        </div>
                    </div>
                    <div id="content-row-2" class="content-row">
                        <img class="grid-image" src="assets/style_TE.png" alt="Description" data-description="The Style of Teenage Engineering">
                        <div class="text-column">
                                            <h3>The Style of Teenage Engineering</h3>
                            <p>
                                Teenage Engineering produce high-end electroacoustic devices with a playful but elegant design. TE are known for using innovative interaction mechanisms to provide a unique user experience to those using their products. To many in the electronic music scene, teenage engineering represents quality and creative freedom.
                            </p>
                            <p>
                                Through Midjourney, we reimagine the electrolarynx as a synthesizer using teenage engineering's trademark style. The ensuing design concept is a sleek and highly functional medical device that offers laryngectomy patients with powerful acoustic synthesis tools.                        </p>
    
                        </div>
                    </div>
                    <div id="solution">
                        <img class="grid-image" src="assets/style_page.png" alt="Description" data-description="Redesigning the electrolarynx using the style of Teenage Engineering">
                    </div>
            </div>


        </div>

        <div class="spacer">

        </div>


        <div id="analogy" class="section">
            <div class="section-main">
                <h2 class="section-title">Analogy</h2>
                <h1 class="section-header">Natural Selection for Architectural Fault Detection</h1>
            </div>

            <div class="background-container">
                <p class="background-description">
                    In Design by Analogy, we develop an architectural tool to solve a specific problem by examining how similar problems are solved in a source domain and transferring that solution to our target domain.

                </p>

                <div class="content-row">
                    <img class="grid-image" src="assets/analogy_problem.jpg" alt="Description" data-description="An example of an architectural failure point that was only realized post construction.">
                    <div class="text-column">
                        <h3>Target Domain:
                            Architectural Failure Points</h3>
                        <p>
                            Architects and clients often realize post construction that certain design decisions do not suit the clients needs and preferences. These unanticipated faults range from mildly annoying to very serious and in the best case can be rectified through renovation, but more often than not are permanent issues that the client has to live with.
                        </p>
                        <p>
                            These faults arise due to inexperience of the architect, thoughtless demands by the client, or other unforeseen environmental factors that only become apparent once the house is built.
                        </p>
                        <p>
                            Finding a way to identify potential failure points early in the design stage would greatly reduce the headache and costs associated with construction, build trust between the architect and client, and improve the clients satisfaction with the project outcome.
                        </p>
                    </div>
                </div>
                <div class="content-row">
                    <img class="grid-image" src="assets/analogy_giraffe.png" alt="Description" data-description="The giraffe is an excellent illustration of how natural selection approaches environmental challenges.">
                    <div class="text-column">
                        <h3>Source Domain:
                            Natural Selection</h3>
                        <p>
                            Giraffes developed long necks in order to reach leaves, fruit and flowers high up in Vachellia or Senegalia trees, which are sought after food sources in the giraffes diet. The lengthing of necks did not occur as a delibrate answer to the specific environmental problem that they faced, but evolved through natural selection.
                        </p>
                        <p>
                            Giraffe individuals with longer necks could graze higher than other terrestrial browsers, allowing them to exploit a band of foliage higher than other animals are capable of accessing, giving them a unique advantage. Individuals that had shorter necks did not have access to this exclusive source of food, and therefore had increased competition, and gradually died out, preventing them from passing their disadvantageous genes to their offspring.
                        </p>
                        <p>
                            This "try-and-fail" solution to the problem of environmental failure points is the analogy we would like to reproduce in our target domain of architecture.
                        </p>

                    </div>
                </div>
    
                <div class="column-container">
                    <div class="image-text-column" id="blending-final">
                        <img class="grid-image" src="assets/analogy_sims.png" alt="Description1" data-description="Our conceptual design for architectural fault detection">
                        <div class="column-text">
                            <h3>Solution:
                                A Natural Selection User Simulation System for Failure Point Detection</h3>
                            <p>
                                We introduce a natural selection based failure point detection system for iterative design development in architecture. At each iteration, the design made by the architect is given to the simulator, which will run experiments.
                            </p>
                            <p>
                                The goal of these experiments is to simulate the behavior of predefined personas inside the building, to automatically detect flaws in the design. All personas that were not satisfied or blocked in their journey will not 'survive' the experiment, but instead of having a new generation of personas for next iteration, it is the building that will be improved.
                            </p>
                            <p>
                                At the end of these simulations, a detailed report is generated with the journey of each persona and their failure point in order to help the architect improve their design.
                            </p>
                        </div>
                    </div>
    
                    </div>
                </div>

        </div>

        <div class="spacer">

        </div>

    </div>
                
    </div>

   <script type="module">

        import { initializePointCloud } from './js/pcloader_modular.js';

        
        const sectionImages = {
            'titlePage': {
                image: 'assets/empathy_moss.png',
                depth: 'assets/empathy_moss_depth.png',
                nMin: 15,
                nMax: 50
            },
            'empathy': {
                image: 'assets/empathy_luca.png',
                depth: 'assets/empathy_luca_depth.png',
                nMin: 35,
                nMax: 60
            },
            'blending': {
                image: 'assets/blending_blend.png',
                depth: 'assets/blending_blend_depth.png',
                nMin: 35,
                nMax: 60
            },
            'context': { // Replace with actual section IDs and image paths
                image: 'assets/context_athens_sq.png',
                depth: 'assets/context_athens_sq_depth.png',
                nMin: 35,
                nMax: 45
            },
            'decomposition': {
                image: 'assets/decomposition_shop.png',
                depth: 'assets/decomposition_shop_depth.png',
                nMin: 35,
                nMax: 60
            },
            'style': {
                image: 'assets/style_device_black.png',
                depth: 'assets/style_device_black_depth.png',
                nMin: 35,
                nMax: 60
            },
            'analogy': {
                image: 'assets/analogy_giraffe.png',
                depth: 'assets/analogy_giraffe_depth.png',
                nMin: 35,
                nMax: 60
            },
            // // Add more sections and images as needed
        };

        var settings = {
            focalDistance: 10,
            near: 5,
            far: 20,
            smoothRadius: 0,
            quadSize: 1.0,
            pointSize: 2,
            downsampling: 2
        };
        var nDistanceInit=60;
        var nDistanceMax=60;
        var nDistanceMin=35;
        var material, meshPoint;
        var renderer, scene, camera, fov = 70, nFov = fov, distance = 500;
        var nDistance = nDistanceInit;
        var displacement = 0, nDisplacement = displacement;

        var lon = 90, lat = 0, nLon = lon, nLat = lat;
        var oDist, oFov, adjustment = 0;

        // Initialize renderers
        scene = new THREE.Scene();

        camera = new THREE.PerspectiveCamera( fov, window.innerWidth / window.innerHeight, .1, 1000 );
        camera.target = new THREE.Vector3( 0, 0, 0 );
        camera.position.y = 500;
        scene.add( camera );

        renderer = new THREE.WebGLRenderer( { antialias: true, alpha: false } );
        renderer.setClearColor( 0, 0 );
        renderer.setSize( window.innerWidth, window.innerHeight );
        renderer.sortObjects = true;

        document.getElementById("titlePage-box").appendChild(renderer.domElement);

        // initializePointCloud('titlePage-box', 'titlePage', 'assets/trashimage.png',  'assets/trashdepth.png')

        // // Initialize all point clouds
        // for (const sectionId in sectionImages) {
        //     const { image, depth } = sectionImages[sectionId];
        //     initializePointCloud(sectionId + '-box', sectionId, image, depth);
        // }

        let pointClouds = {};
        let currentPointCloud = null; // Declare the variable outside
        let pointCloudData = {}; // To store additional parameters of each point cloud



    async function initPointClouds() {
    let loadedPointClouds = 0;
    const totalPointClouds = Object.keys(sectionImages).length;

    for (const sectionId in sectionImages) {
        const { image, depth } = sectionImages[sectionId];
        try {
            const data = await initializePointCloud(sectionId + '-box', sectionId, image, depth, 500);
            pointClouds[sectionId] = data.pointCloud;
            pointCloudData[sectionId] = { minZ: data.minZ, maxZ: data.maxZ, offset: data.offset, adjustment: data.adjustment };
            loadedPointClouds++;

            if (loadedPointClouds === totalPointClouds) {
                // Set the currentPointCloud to the 'titlePage' point cloud
                currentPointCloud = pointClouds['titlePage'];
                scene.add(currentPointCloud); // Add the point cloud to the scene

                // Hide the loading screen
                const loadingScreen = document.getElementById('loadingScreen');
                if (loadingScreen) {
                    loadingScreen.style.opacity = '0';
                    loadingScreen.style.visibility = 'hidden';
                    loadingScreen.style.pointerEvents = 'none';
                }
            }
        } catch (error) {
            console.error('Error loading point cloud for', sectionId, error);
        }

        // Update loading screen text
        document.getElementById('number').innerText = 'Loading ' + (loadedPointClouds - 1) + ' out of 6 projects';
    }
}
        // Call the function to initialize point clouds
        initPointClouds();




        function render() {

            requestAnimationFrame( render );

            // if( nDistance < camera.near ) nDistance = camera.near;

            lon += ( nLon - lon ) * .1;
            lat += ( nLat - lat ) * .1;
            fov += ( nFov - fov ) * .1; 
            // distance += ( nDistance - distance ) * .1; 

            if (nDistance > nDistanceMin) {
                nDistance -= 0.05; // Decrement nDistance
                nDistance = Math.max(nDistance, nDistanceMin)
            }

            distance += ( nDistance - distance ) * .1; 
            displacement += ( nDisplacement - displacement ) * .1; 

            camera.fov = fov;
            camera.updateProjectionMatrix();

            if( meshPoint ) {
                meshPoint.scale.z = adjustment * displacement;
                meshPoint.visible = 1;
            }

            lat = Math.max( - 85, Math.min( 85, lat ) );
            var phi = ( 90 - lat ) * Math.PI / 180;
            var theta = lon * Math.PI / 180;

            camera.position.x = distance * Math.sin( phi ) * Math.cos( theta );
            camera.position.y = distance * Math.cos( phi );
            camera.position.z = distance * Math.sin( phi ) * Math.sin( theta );

            camera.lookAt( camera.target );

            renderer.render( scene, camera );

            }







        

        const navCircles = document.querySelectorAll('.nav-circle');

        document.querySelectorAll('.grid-image').forEach(image => {
        image.addEventListener('click', function() {
            document.getElementById('imageOverlay').style.display = 'block';
            document.getElementById('overlayImage').src = this.src;
            document.getElementById('imageDescription').textContent = this.getAttribute('data-description');
            });
        });

        document.getElementById('closeOverlay').addEventListener('click', function() {
            document.getElementById('imageOverlay').style.display = 'none';
        });



        document.addEventListener('DOMContentLoaded', () => {
            // const titlePageBox = document.getElementById('titlePage-box');
            // if (titlePageBox) {
            //     titlePageBox.style.opacity = '1';
            //     console.log(titlePageBox)
            // }

            let loadedPointClouds = 0;
            const totalPointClouds = Object.keys(sectionImages).length;
            const onPointCloudLoaded = () => {
                loadedPointClouds++;
                document.getElementById('number').innerText = 'Loading ' + (loadedPointClouds - 1) + ' out of 6 projects';

                if (loadedPointClouds === totalPointClouds) {
                    // All point clouds loaded, hide the loading screen
                    if (loadingScreen) {
                        const loadingScreen = document.getElementById('loadingScreen');
                        loadingScreen.style.opacity = '0';
                        loadingScreen.style.visibility = 'hidden';
                        loadingScreen.style.pointerEvents = 'none';
                    }
                }
            };

            // handleSectionVisibility('titlePage', true); // Assuming 'titlePage' is the ID

            const navCircles = document.querySelectorAll('.nav-circle');
            navCircles.forEach(circle => {
                circle.addEventListener('click', () => {
                    const targetSection = document.querySelector(circle.getAttribute('data-target'));
                    if (targetSection) {
                        console.log(targetSection)
                        // we use a polyfill for safari
                        seamless.scrollIntoView(targetSection, {
                                behavior: 'smooth',
                                block: "start",
                        },
                        {
                            duration: 1000 // aprox. the duration that chrome uses,
                        }
                        );

                    }
                });
            });



            });

            window.addEventListener('resize', () => {
                renderer.setSize(window.innerWidth, window.innerHeight);
                camera.aspect = window.innerWidth / window.innerHeight;
                camera.updateProjectionMatrix();
            });

    
    // Function to update the visibility of the navbar circles
function updateNavCircleVisibility(sectionId, isVisible) {
    navCircles.forEach(circle => {
        if (circle.getAttribute('data-target') === sectionId) {
            circle.style.opacity = isVisible ? 1 : 0.5; // Adjust opacity values as needed
        }
    });
}
document.getElementById("titlePage").style.opacity = "1";

function switchPointCloud(sectionId) {
    if (currentPointCloud) {
        scene.remove(currentPointCloud); // Remove the current point cloud from the scene
    }
    
    const newPointCloud = pointClouds[sectionId];
    if (newPointCloud) {
        currentPointCloud = newPointCloud;
        scene.add(currentPointCloud); // Add the new point cloud to the scene
    }
}


let currentSectionId = 'titlePage'; // Initialize to the default section

    let animating = false;
	let isIntersecting = false; // Track the intersection status

let currentIntersectingSection = "TitlePage";


let animatingSectionId = "TitlePage";

let observer = new IntersectionObserver((entries) => {
    entries.forEach(entry => {
        const sectionId = entry.target.id;
        isIntersecting = entry.isIntersecting;

        if (isIntersecting && currentIntersectingSection !== sectionId) {
            currentIntersectingSection = sectionId; // Update the currently intersecting section
            console.log('New intersecting section:', currentIntersectingSection);

            // Start fade-out effect
            renderer.domElement.style.transition = 'opacity 0.7s';
            renderer.domElement.style.opacity = '0';


            // Wait for fade-out to complete
            setTimeout(() => {
                // Handle point cloud swapping
                if (currentPointCloud) {
                    scene.remove(currentPointCloud); // Remove current point cloud from the scene
                }

                const {minZ, maxZ, offset, adjustment} = pointCloudData[sectionId]


                nDistance = parseFloat( settings.focalDistance ) + offset * adjustment;
				nFov = 1 * Math.atan2( .5 * adjustment * settings.near, settings.focalDistance ) * 180 / Math.PI;
				// material.uniforms.size.value = settings.pointSize * nDistance;
				nDisplacement = 1;

				camera.near = .001;
				camera.far = ( settings.far + ( maxZ - minZ ) ) * adjustment;
				camera.updateProjectionMatrix();

				nLat = 0;
				nLon = 90;
                currentPointCloud = pointClouds[currentIntersectingSection]; // Update the current point cloud
                scene.add(currentPointCloud); // Add the new point cloud to the scene

            }, 500); // This timeout duration should match the fade-out transition time
            setTimeout(() => {
                renderer.domElement.style.opacity = '1';
            }, 1000);


        }
        updateNavCircleVisibility(sectionId, isIntersecting);
    });
}, { threshold: 0.1 });

    // Observe each section
    document.querySelectorAll('.section').forEach(section => {
        observer.observe(section);
    });


    render();
    


    </script> 

    
</body>





</html>


